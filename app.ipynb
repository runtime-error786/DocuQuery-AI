{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.schema import Document\n",
    "import fitz  \n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ppt(file_path):\n",
    "    prs = Presentation(file_path)\n",
    "    text = \"\"\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                text += shape.text + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_directory(directory_path):\n",
    "    docs = \"\" \n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            text = load_pdf(file_path)\n",
    "        elif filename.endswith('.pptx'):\n",
    "            text = load_ppt(file_path)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file format: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        docs += text + \"\\n\"  \n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APRIL 2023\n",
      "100 Practical Applications and \n",
      "Use Cases of Generative AI\n",
      "1\t\n",
      "Breakthrough Technology \n",
      "and Promising Prospects \n",
      "3\t\n",
      "What Is Artificial \n",
      "Intelligence (AI)? What is \n",
      "Generative AI? \n",
      "4\t\n",
      "The Importance of \n",
      "Protecting Data Privacy\n",
      "5\t\n",
      "Insufficient Arabic \n",
      "Language Applications \n",
      "for Natural Language \n",
      "Processing\n",
      "6\t\n",
      "Platforms at Risk of Being \n",
      "Sold or Dying Out\n",
      "7\t\n",
      "Difficulties Associated with \n",
      "the Utilization of Generative \n",
      "AI Technologies\n",
      "8\t\n",
      "Are Inputs and Outputs \n",
      "Always Reliable Despite \n",
      "Qua\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"./multi\"\n",
    "\n",
    "docs = load_documents_from_directory(directory_path)\n",
    "\n",
    "print(docs[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_text_into_chunks(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "APRIL 2023\n",
      "100 Practical Applications and \n",
      "Use Cases of Generative AI\n",
      "1\t\n",
      "Breakthrough Technology \n",
      "and Promising Prospects \n",
      "3\t\n",
      "What Is Artificial \n",
      "Intelligence (AI)? What is \n",
      "Generative AI? \n",
      "4\t\n",
      "The Importance of \n",
      "Protecting Data Privacy\n",
      "5\t\n",
      "Insufficient Arabic \n",
      "Language Applications \n",
      "for Natural Language \n",
      "Processing\n",
      "6\t\n",
      "Platforms at Risk of Being \n",
      "Sold or Dying Out\n",
      "7\t\n",
      "Difficulties Associated with \n",
      "the Utilization of Generative \n",
      "AI Technologies\n",
      "8\t\n",
      "Are Inputs and Outputs \n",
      "Always Reliable Despite \n",
      "Quality-Related Concerns?\n",
      "9\t\n",
      "How Can You Engage with \n",
      "and Obtain Information \n",
      "from Generative AI? \n",
      "11\t\n",
      "Reinforcement Learning \n",
      "from Human Feedback \n",
      "(RLHF)\n",
      "Preface\n",
      "Applications and Use Cases\n",
      "1\t\n",
      "ChatGPT \n",
      "3\t\n",
      "Useful Guidelines \n",
      "and Techniques for \n",
      "ChatGPT\n",
      "12\t\n",
      "Use Cases for New \n",
      "Businesses \n",
      "27\t Use Cases for \n",
      "Students\n",
      "42\t Use Cases for Fresh \n",
      "Graduates, Job \n",
      "Seekers and New \n",
      "Employees \n",
      "57\t Use Cases for \n",
      "Employees \n",
      "72\t Midjourney\n",
      "76\t Other Platforms\n",
      "76\t Jasper\n",
      "77\t Syhthesia\n",
      "78\t DALL·E 2\n",
      "79\t Tome\n",
      "----------------------------------------\n",
      "Chunk 2:\n",
      "Students\n",
      "42\t Use Cases for Fresh \n",
      "Graduates, Job \n",
      "Seekers and New \n",
      "Employees \n",
      "57\t Use Cases for \n",
      "Employees \n",
      "72\t Midjourney\n",
      "76\t Other Platforms\n",
      "76\t Jasper\n",
      "77\t Syhthesia\n",
      "78\t DALL·E 2\n",
      "79\t Tome \n",
      "80\t WellSaid\n",
      "81\t\n",
      "Runway\n",
      "82\t Galileo AI\n",
      "83\t Pebblely\n",
      "84\t GPTZero\n",
      "85\t Fliki\n",
      "86\t Meetcody\n",
      "87\t Sheet AI\n",
      "88\t Quillbot\n",
      "89\t MeetGeek\n",
      "90\t ChefGPT\n",
      "91\t\n",
      "MJ Prompt tool\n",
      "92\t Krisp\n",
      "93\t Socratic\n",
      "94\t Talk to Books\n",
      "95\t Podcast.ai\n",
      "96\t Excelformulabot\n",
      "97\t Interior AI\n",
      "98\t Getfloorplan\n",
      "99\t Durable\n",
      "100\t ELSA\n",
      "Table of Contents\n",
      " - 1 - \n",
      "The rise of generative Artificial Intelligence \n",
      "is a major factor in the world’s current rapid \n",
      "advances in digital technologies. With \n",
      "the help of this innovation, we have been \n",
      "able to create material that is incredibly \n",
      "inventive and useful as well as manage new \n",
      "task-accomplishing tools and approaches \n",
      "across several industries. Experts concur \n",
      "that the influence of Artificial Intelligence on \n",
      "the economy will rise in the coming years. \n",
      "These expectations are underpinned by the\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[:2], 1):\n",
    "    print(f\"Chunk {i}:\\n{chunk}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First chunk embedding:\n",
      "[-0.0742826834321022, -0.029410449787974358, 0.06696932017803192, -0.02286062203347683, -0.02098800614476204, 0.052969690412282944, 0.02592637948691845, 0.032274942845106125, -0.028028879314661026, 0.016584163531661034, -0.03299710527062416, -0.003927039913833141, 0.006547821220010519, -0.06945374608039856, 0.04272918403148651, 0.034846287220716476, 0.055202048271894455, -0.038294725120067596, -0.04937104135751724, -0.10260594636201859, 0.01504532527178526, 0.0471486821770668, -0.005048910155892372, -0.0006805926677770913, -0.012040045112371445, 0.036506570875644684, 0.018806664273142815, -0.10860075801610947, 0.048296790570020676, -0.0352928452193737, -0.007574012503027916, 0.11731439083814621, -0.002956823445856571, 0.0224103145301342, -0.06010154262185097, 0.0809231773018837, -0.08818709850311279, -0.020694583654403687, 0.0716385617852211, -0.008787315338850021, -0.07235170900821686, -0.1435173898935318, -0.011138818226754665, -0.04209935665130615, 0.10069553554058075, -0.04361623525619507, -0.0898551270365715, 0.009767216630280018, 0.008875468745827675, 0.03912784904241562, -0.18726027011871338, -0.030848704278469086, 0.08337429165840149, 0.0757785439491272, -0.039224058389663696, -0.08315844088792801, 0.00287471991032362, 0.015271098352968693, -0.03472597524523735, -0.03477014973759651, -0.06882201135158539, -0.07633323222398758, -0.01827051304280758, -0.016219835728406906, -0.03137338533997536, -0.007360121700912714, -0.07783510535955429, 0.025197939947247505, 0.01600773259997368, -0.046323005110025406, 0.028086591511964798, 0.03960559144616127, -0.023312043398618698, 0.04264984652400017, -0.03603507950901985, 0.004465934354811907, 0.0010343501344323158, -0.0844404399394989, 0.03818398714065552, -0.06386740505695343, 0.043095916509628296, 0.02640833519399166, 0.012193256057798862, 0.017858650535345078, -0.10355929285287857, -0.009255660697817802, -0.0032968856394290924, 0.0645860955119133, -0.008860806003212929, 0.02658679708838463, 0.0347418412566185, 0.0012892247177660465, 0.05466470122337341, 0.03357493504881859, 0.04908711835741997, -0.042787715792655945, -0.059747327119112015, -0.01872859336435795, -0.035134270787239075, 0.022388789802789688, 0.03753582760691643, 0.04753788188099861, -0.002684167353436351, -0.05562257021665573, -0.09093651175498962, 0.01988932490348816, 0.006383471190929413, -0.03269277513027191, 0.012582247145473957, -0.08025902509689331, -0.11311162263154984, -0.020827265456318855, -0.04079417884349823, -0.07656224071979523, 0.014582649804651737, -0.05894395709037781, 0.01063199620693922, 0.027191288769245148, -0.0015732052270323038, 0.06046824902296066, -0.0049982741475105286, 0.00804994534701109, 0.01067203190177679, -0.00526786083355546, -0.006276054307818413, -0.05614570155739784, -0.04821734130382538, 1.2707774249744466e-32, 0.005993004888296127, -0.016768360510468483, -0.06284765899181366, 0.14055560529232025, 0.0018421036656945944, -0.006155982613563538, -0.010563810355961323, 0.0342731699347496, 0.002230333862826228, -0.10743158310651779, 0.02203254960477352, 0.027746815234422684, -0.06255308538675308, 0.046436503529548645, 0.029238758608698845, -0.03925934433937073, -0.0026583343278616667, 0.06454648822546005, 0.020109502598643303, -0.026598617434501648, 0.08956589549779892, -0.022451119497418404, 0.03709610924124718, 0.07668109983205795, 0.013069608248770237, 0.05780821293592453, 0.08612921088933945, -0.07554753124713898, 0.08186431229114532, 0.034054625779390335, -0.003803993109613657, -0.01085320021957159, -0.0861126258969307, -0.0010464998194947839, -0.04066736623644829, 0.07630372792482376, -0.019792132079601288, -0.04183737561106682, 0.0030889941845089197, -0.003876548493281007, -0.10220460593700409, -0.0011094332439824939, 0.091525137424469, 0.035403650254011154, 0.015054808929562569, -0.01285719033330679, 0.054804589599370956, -0.05640330910682678, 0.029346920549869537, 0.022442586719989777, -0.04707079008221626, 0.05895739793777466, 0.026671594008803368, 0.010990562848746777, 0.04344961792230606, -0.03255520388484001, -0.06795451045036316, -0.005054440349340439, -0.00024960970040410757, -0.004890693351626396, 0.015544886700809002, 0.03305817395448685, -0.03312993422150612, 0.018958814442157745, -0.027678735554218292, 0.029362022876739502, 0.03476385027170181, -0.055609989911317825, 0.041035111993551254, 0.0306549035012722, 0.052083756774663925, 0.014034904539585114, 0.008345101960003376, 0.019119232892990112, -0.017063219100236893, 0.043090831488370895, -0.008461888879537582, -0.05356141924858093, 0.05568961054086685, -0.00029236669070087373, -0.06980684399604797, 0.008615849539637566, 0.03632313385605812, -0.0026484662666916847, 0.018801698461174965, 0.012452522292733192, 0.07835086435079575, -0.0036892665084451437, 0.01037211436778307, 0.07176359742879868, -0.04991227760910988, 0.007188744843006134, -0.006225431337952614, 0.12098760157823563, 0.009737657383084297, -1.263223404402475e-32, -0.027586165815591812, 0.02629600279033184, -0.09930896013975143, 0.0428040437400341, -0.005216054618358612, -0.017797915264964104, -0.02004014141857624, 0.04148967191576958, 0.06852555274963379, -0.07084137201309204, -0.07118262350559235, 0.006317255087196827, 0.05490325018763542, 0.010664908215403557, -0.05641752853989601, -0.03899431973695755, -0.012968177907168865, -0.056885212659835815, -0.02302657812833786, 0.06936714053153992, 0.02175694704055786, 0.08940806239843369, -0.17594625055789948, 0.06010015308856964, 0.06440842151641846, 0.01309260819107294, -0.050559986382722855, -0.027251701802015305, 0.02974466234445572, 0.004290968645364046, 0.012152660638093948, -0.06967823207378387, -0.06580818444490433, 0.0489259734749794, -0.03900361806154251, 0.029283760115504265, 0.12372563779354095, -0.07745618373155594, -0.02830735221505165, 0.07388845831155777, 0.08615215867757797, -0.005530449561774731, -0.07898344099521637, -0.052556123584508896, -0.04353899136185646, -0.037558361887931824, -0.1069648340344429, -0.003771071322262287, 0.04370948299765587, -0.012686480768024921, 0.040174856781959534, -0.013211550191044807, -0.007824510335922241, -0.08002301305532455, -0.026015080511569977, -0.031827162951231, 0.05289098992943764, -0.026425644755363464, -0.03436638042330742, 0.049198150634765625, -0.04608998820185661, 0.007418317254632711, 0.06780772656202316, -0.04381755366921425, -0.038241904228925705, -0.0635073184967041, 0.03443184867501259, 0.0602727010846138, -0.005508263595402241, -0.06644485145807266, 0.0378604382276535, 0.01117767859250307, -0.04646020010113716, -0.016960883513092995, 0.04940503463149071, 0.04781884700059891, 0.0007440921035595238, -0.04040762037038803, -0.026911845430731773, -0.05743619054555893, 0.03710359334945679, -0.028165804222226143, 0.02764035388827324, 0.03827379643917084, 0.05779479444026947, 0.08239366859197617, 0.06916949152946472, -0.03102835640311241, -0.009159233421087265, 0.0018199078040197492, -0.07016700506210327, -0.01206130813807249, -0.05156581848859787, 0.08768964558839798, -0.00433537270873785, -5.89539510542636e-08, -0.008946835063397884, -0.04755786433815956, 0.06826915591955185, 0.02377280965447426, 0.07306913286447525, -0.004662095569074154, -0.08712222427129745, 0.06640782952308655, 0.0016034296713769436, -0.015324271284043789, -0.016699131578207016, -0.013990170322358608, -0.0691351443529129, -0.04933055490255356, 0.1099986657500267, 0.037804629653692245, -0.023411298170685768, -0.02226214110851288, -0.021206239238381386, -0.058178286999464035, 0.1597878485918045, -0.0022864837665110826, -0.0757843405008316, -0.022132184356451035, -0.02373426966369152, -0.018604712560772896, 0.02926185168325901, -0.0017472661565989256, -0.11296751350164413, 0.02158988267183304, -0.025737378746271133, 0.034936897456645966, -0.0002317337493877858, -0.021212149411439896, 0.10463521629571915, 0.05736424773931503, 0.021393800154328346, -0.0611761137843132, -0.019838949665427208, -0.021172482520341873, 0.007943988777697086, 0.01210465282201767, -0.027965694665908813, -0.015518569387495518, 0.017620142549276352, -0.031661391258239746, -0.09263594448566437, -0.08593203127384186, 0.007186152972280979, 0.01024745311588049, -0.0024556899443268776, -0.04209589958190918, 0.049558550119400024, 0.05945304408669472, 0.12581564486026764, 0.029857495799660683, 0.05527456849813461, -0.04174391180276871, 0.03316598758101463, 0.041947901248931885, 0.09603364765644073, 0.046954117715358734, -0.008507325313985348, 0.03439649939537048]\n"
     ]
    }
   ],
   "source": [
    "chunk_embeddings = [embeddings.embed_query(chunk) for chunk in chunks]\n",
    "\n",
    "print(f\"First chunk embedding:\\n{chunk_embeddings[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "ASTRA_DB_API_ENDPOINT = 'https://7b4f4f6f-5c2c-4614-839b-f064568f5bea-us-east-2.apps.astra.datastax.com'\n",
    "ASTRA_DB_APPLICATION_TOKEN = 'AstraCS:hkuBWtKhPLFmRuGcyrlclTdN:0c276a7f4e440ec2463eb67554565e620a0e95a2c8d0c8e603c47093a41697f5'\n",
    "ASTRA_DB_NAMESPACE = 'your_namespace'  \n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"db\",\n",
    "    embedding=embeddings,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_insert = [\n",
    "    Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\"embedding\": embedding}  \n",
    "    )\n",
    "    for chunk, embedding in zip(chunks, chunk_embeddings)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['43ef3e8d17c3400f8a30ef672b0f72d6',\n",
       " '4f6a27a2a8554cf0a63c5af0ff2a6cdd',\n",
       " '18780902694b4cd9b07834eec11979e4',\n",
       " 'b226eec180b946ca9a9dc1049e5755b0',\n",
       " 'ed8ae32b583f49868d9d764b4b928fe0',\n",
       " 'f7551a03cedc4a5da97bd4b65c241722',\n",
       " '74f6389dd4e540988417d5718c1459c1',\n",
       " '6bbc23fc235b4d2b9073ba1b9fdeb7cc',\n",
       " '5bbf81510f404223afc5b4f4cf0e7529',\n",
       " '45bf5c0c916544a595fd51f4809c1e15',\n",
       " 'df9dfae136764bf29ff24a27c61a3133',\n",
       " 'b1b69b2f55c8468989309bd5d5079981',\n",
       " '0e843cffc4a94f35ad19cd9384d4ce4a',\n",
       " '5e2c5077fc26406bbd1cf350deceb681',\n",
       " '57022fe8328b4f3f8cc5524bbbdc171e',\n",
       " 'a4b097e38a7f471abfc4cbaf73e565dc',\n",
       " 'a0e6bdf4faaa4d498032a6ce6216373c',\n",
       " '95ae4850e4ff40a8b52df53eedbe91cf',\n",
       " '18a31e0f83b5431aa168984d07700e7b',\n",
       " '4fc2174b9e3d4cdd96654a70752261ca',\n",
       " '9d521f2ea6a94b94af40ebaf006fd2bf',\n",
       " 'b126e5a258cd4397a77c4538ecb14e3c',\n",
       " 'e5b94b3046c947df833a1ede978bdaac',\n",
       " '2754abb3976540dc8a4cf2009705c242',\n",
       " '23321099e69546e082f8c71f01bd65ea',\n",
       " 'bfcfc4932f9747f086ca3de9ca8f53b5',\n",
       " '2395bcba46ba4abfb25958fa1fec62df',\n",
       " '14cab42d986a4bf8b1013336591d9ba2',\n",
       " '40956def7fce4ff79e01edf7ad1c1100',\n",
       " '71856622aeef485dbf44c5ee6e476c1a',\n",
       " '72caa015874441e0935c33d26be3a2fd',\n",
       " 'd6818ae31f3344f9b45cbc3a53a9d0f8',\n",
       " 'f188a0f0076d4fe7bc3137a2f15c8d8e',\n",
       " '9b1007d57d494c0bb1cbaaaf62230737',\n",
       " 'bb0ca749436e43a7acf0533f5fd3e8ed',\n",
       " 'c979f3ada5214c0e8fc62797622f643b',\n",
       " '63058dedbcf247968d9b98be7a750e74',\n",
       " '49286dc185654a0b82724c3cca092ee0',\n",
       " 'c9d6e68440c44443a1084888ad6d22a6',\n",
       " 'd540de0e52ea457ba2b08e5cbe48df1f',\n",
       " 'd1ea33476e8c478c9b0d32b30ee6cf0b',\n",
       " '621f28758b964aa295fadef84fe961e3',\n",
       " '20a40b48660448b7a8f02bee68d6c29e',\n",
       " '4c9e82c8544342c7be8449eb1b656c6a',\n",
       " '31f0a675b26e4eac9243b54be35213cb',\n",
       " 'fdbce8d1b1e449d3875cc4e42d7c2c92',\n",
       " 'fa8ed396833b44b3bf9f4be2e8a837e5',\n",
       " '5c7ea486477b42699cd22f4900603f37',\n",
       " '2287f49115264398bbc570a97d41b262',\n",
       " '409aea9487c04f7aa143893bb856332b',\n",
       " 'dca1327375b7435b8c70abb58d48e6aa',\n",
       " '1c29ece1d2494964919033cf3e7bbc6c',\n",
       " 'd08d9c667a434d8a973bed91469a4a38',\n",
       " '104a53a77bce491ab98efcbe4d141f1f',\n",
       " 'a317280afe884bfda99a79e079ad2321',\n",
       " '3cfdadf314104e2081d946501e14ad67',\n",
       " '6f7a2e1f9a1d42149be882d25acf45bd',\n",
       " '99fb3b439b224223b58c3eb453729516',\n",
       " '2beef058e5f042839dc28569fe948469',\n",
       " 'f5d08ba9de6f4770868f5a3ee8e53045',\n",
       " '5e2c6f8ee17c46fab0aa08662435a0cc',\n",
       " '7b4abadd82bb49ba9952e1282400ec6f',\n",
       " '8319a21473144b5a8d3656fee4455272',\n",
       " 'e42428a4bbc04609ac5da3a8bcadf073',\n",
       " 'de21420be23f47abacd33508d3d973f9',\n",
       " '0aa7d8bd8bf44e9a9428c2a52c4570ea',\n",
       " '1b5cccf170a74a248ce21fb5e55f5e68',\n",
       " 'e0763ac19f254885b7b26167c1c0094c',\n",
       " '89ae45bd9008432ea8dd489e38257503',\n",
       " 'c72ef44fa40347d790c9c4bb880e7081',\n",
       " 'ec1582795f894ace8ab18bd7aa463092',\n",
       " '57a02fcb0ba249e6bbab4f9884785e9d',\n",
       " 'e8368ec9493c40809ba7693ced857109',\n",
       " '869c16773fb340b0b0111f64803e9af3',\n",
       " '06ebdc63404c431181276a07c63fe74b',\n",
       " 'c2235981dfdb42d79f120e0a62f22a8d',\n",
       " '7fc8570b02fe41f3be1b59b24b2938bf',\n",
       " '9c216e22281c46688fd9e3b40aa5a02e',\n",
       " '71d2ae0475a44689a97200ddc7a5622b',\n",
       " 'aa6f0f4488a4466a877dae472e11015d',\n",
       " 'a19d58e7fea84536b62703a6ee59b990',\n",
       " 'e9c0e466c46e4c6a88f39f015e108b8e',\n",
       " '6df1c382420f4bf080915a7c506be1ee',\n",
       " 'f9508823f2024d2797b6af8a08c5e392',\n",
       " 'fa5882d85e6c4084847bc77092b84d47',\n",
       " '573354d7dd53456baac0dee6134f77c1',\n",
       " '9911317862da423499f5e7187c1738aa',\n",
       " '01c0e01ce9aa426ba5df90bd47d856bc',\n",
       " '4a4db4841f1641d08b43ef67262d26f3',\n",
       " '619f4558f7cc4f0f8e17baabba3ab820',\n",
       " '6c3c93b117724980b9554aac7b9f878d',\n",
       " 'e906a65276a44682a84f1824d2439e9b',\n",
       " '47b82e9b452945efa6b56772dd4d0e4b',\n",
       " 'e93d22bf259d4fd790c6aef136cdce66',\n",
       " '7a5f6571ab914da289f4ee1c73f4aed9',\n",
       " 'b7a95860f84c42ffa0c072a5d940e105',\n",
       " '45aaef8ceb9142c380cd328a212b4f91',\n",
       " '8461945b463d45a9abe7d54e4b537f83',\n",
       " '1276e6064a4d47768f8b026bfe838172',\n",
       " 'e0e645c0d8184e909149638978f34ec0',\n",
       " '2e27d741709a4c06a255acc4c91908cc',\n",
       " 'fd43e5e2a91f4bdfa9c610ee2e2fd405',\n",
       " '5811a6b2e61648bc9b9982a40a1955b1',\n",
       " 'c8ec126387914d71986e9f66286ddcbe',\n",
       " '2c199ba668534b2b8c02aeef34c6dd18',\n",
       " 'c9c8160b7e974caea002ce2588577098',\n",
       " 'fe64a27dab86438bb7c69efd8a5cd218',\n",
       " '417b5c596cfd431087bd56f808a06edc',\n",
       " 'f14e04eef7634177baeebdf3aa6be7a3',\n",
       " '07ad4b1631594417a8e37a054f903422',\n",
       " 'a690360fbd0341bbbec52a1d5f175854',\n",
       " '0f56a59e35374e72bbdc2110d71ade23',\n",
       " 'be721634dcf946ada2c08535146ce2d9',\n",
       " '6b51e037505d4ca998890dc2e23f231f',\n",
       " 'dc0b55e1b59440db94d3f27d6f140e75',\n",
       " 'e250dc48bbb148cdb5228b1649195986',\n",
       " '5d2fd7e1c62c4e51b4cb63c0e86a13bc',\n",
       " '56e4c679c18644acb766b6769b834fc4',\n",
       " '9c190a001dd2409a8bad94644feb5335',\n",
       " '579eb34b4079462996db7d3961b60761',\n",
       " 'd898301a8e8841cdbb2ebbc1563dc79b',\n",
       " 'fd486168a32443e6af2d953a58ef9686',\n",
       " '3b0d78b1daa44c8c94c57c161c36375c',\n",
       " '93e25b666dd54ea0aadb89ec3c424daf',\n",
       " '6d0160fb158645f391cd16d915f07db9',\n",
       " '72f8ccdc0859489f957629492c3be241',\n",
       " '544ef15ba5804b5082c6d8b310c60eb5',\n",
       " 'd187c131072b4f98969cf89bb913c29e',\n",
       " 'e9ae25e9229b493bbfd0c7841df877e6',\n",
       " '7d9cdfbe4c3c4054ad29c2b108b6e75c',\n",
       " '9b8e74edca4848049b1aaa50d3cc0b99',\n",
       " '3fa39e4041e14a999d03a74b392deb9d',\n",
       " 'a53b6bd3f34b4b52b7d83260f2f8f0f6',\n",
       " '83613e1e471649a1b0fdeb058d1f9a61',\n",
       " '1c190cb52807410e9d945dba13a0dfbc',\n",
       " '6f27ff428fd44b0ba7166bea90b0db12',\n",
       " '87df988ceed54caaaa864c1a4c33fdda',\n",
       " '8d881748cf0743fc85e1bdbced17e430',\n",
       " '5fc9072bac364f45be2c606621f2fdf0',\n",
       " '42a77dff348d47b49bdaee6a407c464e',\n",
       " '32f0a83df1434ba0bee9d7034aee8567',\n",
       " '766484d8ac7f45ac9a9aeb824c0a9481',\n",
       " '90ab4243856540608feae133a9c50051',\n",
       " '0638bcf977c64df8b4f95e51f32aed02',\n",
       " '194275143a6d47e4993d11eea39f4027',\n",
       " 'a74b50a775754b95ac31d70878419063',\n",
       " '861201d967f94861aedb5fdaa9081681',\n",
       " '9b7df5cc8783414c904e0423c4d2b3da',\n",
       " '05ae1bbef2514ce5b89c696f773de578',\n",
       " 'a8f403d27637412a8caa63135c28cb3d',\n",
       " '141246a2c388412fad579c1e4ac89ad1',\n",
       " '6222a42729cf42d18b8157404847aa7a',\n",
       " 'aac3dc3ddce4491c8024f9261ad5fd4a',\n",
       " '69f3929abca945a4acf2e0a43f9d63f5',\n",
       " '439c7cdf7bb041aa8835c4a7c2ff17ae',\n",
       " '2cfd4c1f789c48a98f6b46ec0b3eebcf',\n",
       " 'b1a3d498f6104f3283441bf32d76422f',\n",
       " '881caa3ca9304ad68fca8ec798282d07',\n",
       " 'e8eb71cf02c940f391211b118c44476d']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful assistant with access to a large database of documents. Please provide a comprehensive and detailed answer to the user's query based only on the relevant information provided below. \n",
    "\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "Relevant Information:\n",
    "{relevant_documents}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "llama = Ollama(model=\"llama3\")\n",
    "llm_chain = LLMChain(\n",
    "    llm=llama,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_generate_answer(user_query):\n",
    "    results = vector_store.similarity_search(query=user_query, k=3)\n",
    "    \n",
    "    relevant_documents = \"\\n\".join([doc.page_content for doc in results])\n",
    "    \n",
    "    response = llm_chain.run({\n",
    "        \"user_query\": user_query,\n",
    "        \"relevant_documents\": relevant_documents\n",
    "    })\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, here are some applications of Generative AI:\n",
      "\n",
      "1. **Art and Design**: Generative AI can be used to create new and original artistic content, such as images, music, or even videos.\n",
      "2. **Content Creation**: This technology can generate new content, including text, images, or audio files, which can be used in various industries, such as entertainment, marketing, or education.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI can be used to develop more advanced chatbots and virtual assistants that can understand and respond to user queries in a more natural and human-like way.\n",
      "4. **Language Models**: Large-scale language models like OpenAI's GPT-3 can be trained on vast amounts of data to generate new text content, summarize long documents, or even assist with writing tasks.\n",
      "5. **Image Generation**: Generative AI models can create realistic images based on a given prompt or input, as demonstrated by the example provided from Midjourney.\n",
      "\n",
      "These applications are made possible due to the advancements in deep learning and the development of models like Generative Adversarial Networks (GANs), which consist of a generator and a discriminator. The generator creates new data instances that resemble the training data, while the discriminator evaluates whether the generated data is similar to the training data or not.\n",
      "\n",
      "In addition, generative AI has various potential applications across industries, including:\n",
      "\n",
      "* **Media and Entertainment**: Generative AI can be used to create new content, such as movies, TV shows, or music, that can help reduce costs and increase efficiency.\n",
      "* **Healthcare**: This technology can be used to generate personalized treatment plans, diagnose diseases, or even assist with medical research.\n",
      "* **Finance**: Generative AI can be used to analyze large amounts of financial data, predict market trends, or even generate investment strategies.\n",
      "\n",
      "However, it's essential to note that there are also limitations and challenges associated with generative AI, including the need for substantial computational resources, regular maintenance and updates, and addressing vulnerabilities and biases in the models.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Give some applications of generative ai?\"\n",
    "answer = search_and_generate_answer(user_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Is it possible to make snake game using reinforcement learning?\"\n",
    "answer = search_and_generate_answer(user_query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
